################################################################################
# .env.sample ‚Äî OES GenAI Micro-Apps
# ------------------------------------------------------------------------------
# Copy this file to `.env` and fill in the actual secrets locally.
# This configuration supports all current and upcoming OES micro-apps:
#   - Alt-Text Generator
#   - Umich Feedback Bot
#   - Visual Transcription Tool
#   - CPS Import Tool
#   - and other Streamlit-based GenAI utilities.
#
# Maintainer: Imaad Fakier (Senior GenAI Developer, OES Solutions)
################################################################################


###############################################################################
# üîí ACCESS & AUTHENTICATION
###############################################################################
# Protects access to each Streamlit app with a hashed passcode.
# Generate hash:
#   python3 -c 'import hashlib; print(hashlib.sha256("my-secret-code".encode()).hexdigest())'
ACCESS_CODE_HASH=


###############################################################################
# ü§ñ MODEL PROVIDERS (LLMs)
###############################################################################
# These keys power GPT-4o, Claude, Gemini, and Perplexity integrations.
# Provide only those relevant to the specific app you're running.

# --- OpenAI Models (GPT-4o, GPT-4-Turbo, etc.) ---
OPENAI_API_KEY="sk-proj-xxxxxx"

# --- Google Generative AI (Gemini/PaLM) ---
GOOGLE_API_KEY="AIxxxxxx"

# --- Anthropic Models (Claude 3 / 3.5) ---
CLAUDE_API_KEY="sk-ant-xxxxxx"

# --- Perplexity AI Models (Search-Augmented / Reasoning) ---
PERPLEXITY_API_KEY="pplx-xxxxxx"

# Optional Azure-OpenAI compatibility if used by enterprise apps
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=


###############################################################################
# üß† MODEL CONFIGURATION OVERRIDES (optional)
###############################################################################
# Used to globally control temperature, tokens, or override defaults.
# Example:
#   LLM_TEMPERATURE=0.4
#   MAX_TOKENS=2000
LLM_TEMPERATURE=
MAX_TOKENS=


###############################################################################
# üíæ STORAGE / LOGGING CONFIGURATION
###############################################################################
# Choose one backend for run logs and telemetry.

# (1) Google Sheets ‚Äî lightweight default logger
# Example: https://docs.google.com/spreadsheets/d/<YOUR_SHEET_ID>/edit#gid=0
GSHEETS_URL=
GSHEETS_WORKSHEET_OVERRIDE=Sheet1

# (2) SQLAlchemy-compatible database URL (optional, for future expansion)
# Example: postgresql+psycopg2://user:pass@host/db
SQLALCHEMY_URL=


###############################################################################
# üß© RAG PIPELINE & VECTOR DATABASE CONFIGURATION
###############################################################################
# Used by knowledge-retrieval / embedding-based apps (e.g. Feedback Bot, CPS Import)
# and for the upcoming ‚ÄúClient Data Framework‚Äù.

# MongoDB connection (Atlas or local instance)
MONGO_DB_URI="mongodb+srv://xxxxx/"

# Database & collection names
DATABASE_NAME="vectorDatabase"
META_COLLECTION="filesMetadata"
EMBEDDINGS_COLLECTION="vectorEmbeddings"


###############################################################################
# üñºÔ∏è MEDIA & FILE HANDLING
###############################################################################
# Optional: path or bucket for temporary upload storage.
MEDIA_TEMP_PATH=tmp_uploads/


###############################################################################
# üß± DEPLOYMENT METADATA
###############################################################################
# Used for internal tracking and environment-specific behavior.
ENVIRONMENT=development        # options: development | staging | production
APP_VERSION=1.0.0
APP_NAME=Alt Text Generator


###############################################################################
# üß∞ DEBUGGING & LOGGING
###############################################################################
# Enable verbose logs and Streamlit debug output (true/false).
DEBUG_MODE=false

# Whether to display LLM token cost in sidebar (Alt-Text Generator).
DISPLAY_COST=true
